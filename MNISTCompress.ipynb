{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "lr=0.01\n",
    "momentum=0.5\n",
    "epochs=2\n",
    "log_interval=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         if args.cuda:\n",
    "#             data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "#         if args.cuda:\n",
    "#             data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.327337\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.306440\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.251766\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.281436\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.265142\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.250026\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.173754\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.072551\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.142535\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 1.930265\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.992997\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.788385\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.640832\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.631914\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.372564\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.380614\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.452266\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.327140\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.062072\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.114332\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.117932\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.806282\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1.105020\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.948299\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.060805\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.814717\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 1.247646\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.812236\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.722862\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.800621\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.953167\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.836822\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.752642\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.667207\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.908567\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.858301\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.786596\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.674876\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.574753\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.780349\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.701300\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.692287\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.543855\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.803721\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.411123\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.703875\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.625589\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.634068\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.940874\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.630582\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.739573\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.628441\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.651337\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.662153\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.528920\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.492652\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.497738\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.564144\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.793476\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.553604\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.501142\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.411482\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.521411\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.821834\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.514053\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.406860\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.492836\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.622293\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.584864\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.619037\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.498569\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.559631\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.486670\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.686821\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.579671\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.594523\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.763917\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.503544\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.480473\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.400989\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.634881\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.368032\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.529141\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.496499\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.317082\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.582534\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.473359\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.369231\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.604197\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.306025\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.443124\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.559384\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.412641\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.410481\n",
      "\n",
      "Test set: Average loss: 0.1957, Accuracy: 9400/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.577760\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.563595\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.513844\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.530853\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.424877\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.784919\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.804066\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.430299\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.423664\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.467647\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.587636\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.388821\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.443039\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.397369\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.319988\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.474280\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.500607\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.265584\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.335045\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.360617\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.431746\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.608960\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.392105\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.325164\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.303461\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.649007\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.288795\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.338175\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.495269\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.508072\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.409349\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.453811\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.311320\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.280796\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.474573\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.396356\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.666949\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.471521\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.256907\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.949150\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.514919\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.477555\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.589403\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.303793\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.461320\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.264730\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.602748\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.279597\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.395386\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.365105\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.323501\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.205334\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.391985\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.276586\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.358011\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.214605\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.488054\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.490389\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.274870\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.456897\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.589615\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.232277\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.391734\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.718385\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.466020\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.287052\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.470651\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.306854\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.447597\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.664407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.314469\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.272589\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.656277\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.362533\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.424803\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.256191\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.299532\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.355502\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.312200\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.273123\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.286899\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.523901\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.328993\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.276344\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.413681\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.321205\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.280560\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.627433\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.343604\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.327446\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.299814\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.391865\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.318596\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.342505\n",
      "\n",
      "Test set: Average loss: 0.1261, Accuracy: 9606/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1,epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       "   0.2128  0.2661  0.2396 -0.1836 -0.3214\n",
       "   0.0157  0.1445  0.2532 -0.0322 -0.2574\n",
       "  -0.0198  0.0518  0.3674  0.1567 -0.0764\n",
       "  -0.2078 -0.0753  0.3650  0.3314  0.3167\n",
       "   0.0271  0.0753  0.2105  0.1834  0.0159\n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       "   0.0091 -0.0887  0.2363 -0.0788 -0.0898\n",
       "   0.1534  0.1306  0.2471  0.2930 -0.0520\n",
       "  -0.1567 -0.1610  0.1837  0.1065  0.1585\n",
       "   0.0767 -0.0614 -0.1659  0.1720  0.0434\n",
       "  -0.3042 -0.2339 -0.0299 -0.2120  0.1300\n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       "  -0.1439  0.1628  0.0856 -0.0226 -0.1260\n",
       "  -0.1116 -0.0772  0.2109  0.0476 -0.2457\n",
       "  -0.1226  0.0633  0.1716  0.1777 -0.2553\n",
       "  -0.0661  0.0993  0.1912  0.2740  0.2219\n",
       "   0.2091  0.2903  0.2456  0.4195  0.4125\n",
       " \n",
       " (3 ,0 ,.,.) = \n",
       "  -0.0737  0.0990 -0.2314 -0.1565  0.2563\n",
       "  -0.1747 -0.0674 -0.2561  0.1521  0.2682\n",
       "  -0.1640 -0.0754 -0.1645  0.1075  0.2138\n",
       "   0.0290  0.0320 -0.1092 -0.0362  0.2153\n",
       "  -0.1576 -0.0551 -0.0627  0.2720  0.0777\n",
       " \n",
       " (4 ,0 ,.,.) = \n",
       "   0.2749  0.1944 -0.1642 -0.1272 -0.1396\n",
       "   0.2183 -0.0365 -0.2747 -0.2110  0.1612\n",
       "   0.1247 -0.0256 -0.0554  0.2436  0.2308\n",
       "   0.1862  0.1427  0.0715  0.0820  0.2831\n",
       "  -0.0634 -0.1533 -0.0731  0.1023  0.0338\n",
       " \n",
       " (5 ,0 ,.,.) = \n",
       "  -0.1508 -0.1158 -0.0891 -0.2971 -0.1980\n",
       "  -0.0848 -0.2057 -0.1477 -0.2028  0.1333\n",
       "  -0.1802 -0.1165 -0.0720 -0.1605  0.2590\n",
       "  -0.1247 -0.0492 -0.1875  0.1395  0.1957\n",
       "  -0.0752 -0.0601 -0.0150  0.2703  0.2265\n",
       " \n",
       " (6 ,0 ,.,.) = \n",
       "  -0.0631  0.1823 -0.0714  0.1108 -0.1504\n",
       "  -0.1046 -0.1651 -0.1279  0.2267  0.0727\n",
       "   0.0866 -0.0946 -0.1843  0.0547 -0.0425\n",
       "  -0.1937  0.0140  0.1033 -0.1091 -0.0951\n",
       "  -0.0115 -0.2019 -0.2121 -0.1127 -0.0479\n",
       " \n",
       " (7 ,0 ,.,.) = \n",
       "  -0.0718 -0.2162  0.1387  0.1459  0.2444\n",
       "  -0.1471 -0.0514  0.1238 -0.0165  0.3950\n",
       "  -0.2738 -0.0149 -0.0195  0.3147  0.1650\n",
       "  -0.1093  0.0891  0.1053  0.5058  0.2993\n",
       "   0.0764  0.3043  0.2321  0.2654  0.1887\n",
       " \n",
       " (8 ,0 ,.,.) = \n",
       "  -0.1175  0.1275  0.0757 -0.1335  0.0019\n",
       "  -0.0526 -0.0913 -0.2381 -0.2459 -0.0273\n",
       "  -0.0916  0.0490 -0.2299 -0.0171 -0.0429\n",
       "   0.1026  0.0308 -0.0228  0.1651 -0.1342\n",
       "  -0.0642  0.1853  0.2888  0.3142  0.0129\n",
       " \n",
       " (9 ,0 ,.,.) = \n",
       "   0.1522  0.2451 -0.1192  0.0113  0.1628\n",
       "   0.3287  0.0562  0.3097  0.0714 -0.1256\n",
       "  -0.0056 -0.0050  0.3163  0.1875  0.0795\n",
       "   0.1045 -0.1210  0.0380  0.2664  0.0127\n",
       "  -0.0595 -0.0271 -0.0128 -0.1908  0.1512\n",
       " [torch.FloatTensor of size 10x1x5x5], Parameter containing:\n",
       " -0.0032\n",
       "  0.0022\n",
       "  0.1817\n",
       "  0.1100\n",
       "  0.1303\n",
       "  0.2305\n",
       " -0.0542\n",
       "  0.0057\n",
       "  0.0252\n",
       "  0.1997\n",
       " [torch.FloatTensor of size 10], Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       "  -7.7652e-02  3.4614e-02 -8.8260e-02 -3.0657e-02  1.1410e-02\n",
       "  -5.1895e-02  7.3741e-02 -3.6333e-02  2.7281e-03 -6.3035e-02\n",
       "   1.7873e-03  2.4663e-02 -6.6437e-02 -1.0187e-01 -3.4793e-02\n",
       "   1.8305e-02 -8.2180e-02 -3.9401e-02 -7.4846e-02 -3.5981e-02\n",
       "   1.9486e-02  6.1374e-02 -1.7642e-02 -2.2890e-03 -3.3710e-02\n",
       " \n",
       " (0 ,1 ,.,.) = \n",
       "   5.5989e-02  5.6606e-02 -2.3458e-02 -1.2595e-02 -5.3017e-02\n",
       "  -6.1963e-02 -3.7892e-04 -2.6983e-02 -5.3699e-02 -4.0574e-02\n",
       "   1.6646e-02 -1.0174e-02 -8.9954e-02 -7.8483e-02 -1.9509e-02\n",
       "  -4.1603e-02 -2.3816e-03 -2.6562e-02  2.4484e-02  4.7991e-02\n",
       "  -5.5400e-02 -4.1052e-02 -4.2244e-03  3.6213e-02  1.0086e-02\n",
       " \n",
       " (0 ,2 ,.,.) = \n",
       "  -8.5429e-02  8.0423e-02  2.3636e-02 -6.9460e-02 -1.5315e-02\n",
       "  -7.7678e-03  7.2859e-02 -3.6987e-02 -1.2522e-02 -4.5186e-02\n",
       "  -1.0504e-02  1.1947e-02 -1.0175e-01  5.1345e-03  4.4382e-02\n",
       "  -2.8208e-02  5.2093e-03 -9.0747e-02 -5.5209e-03 -1.9305e-02\n",
       "   7.0401e-02 -3.5077e-02  4.7990e-02  6.6198e-02 -5.9677e-02\n",
       "    ...\n",
       " \n",
       " (0 ,7 ,.,.) = \n",
       "   4.3575e-02  9.8056e-02  7.5455e-02 -8.5456e-02  4.2197e-02\n",
       "   7.8533e-02  8.3034e-02  4.1399e-02  6.1599e-03  5.6505e-02\n",
       "   6.3450e-02  9.5853e-02 -5.1113e-02 -6.0634e-02  4.3138e-03\n",
       "   3.1584e-02  4.1255e-03 -4.2028e-02 -3.7523e-02 -3.0928e-02\n",
       "   3.9368e-02 -7.3634e-02 -4.0086e-02  3.6493e-02  1.5962e-02\n",
       " \n",
       " (0 ,8 ,.,.) = \n",
       "   1.3383e-02 -5.1415e-02 -1.3833e-02  6.5372e-03 -7.8979e-03\n",
       "  -2.7645e-02  6.1129e-03 -2.4996e-02  3.9922e-02  2.2022e-03\n",
       "  -2.9684e-02 -3.1802e-02 -2.8030e-02  3.4757e-02  5.6568e-02\n",
       "  -6.9756e-02 -6.6191e-02 -1.2072e-02  5.0716e-02  1.3553e-02\n",
       "  -4.0526e-02 -2.3764e-03  3.4656e-02  7.9143e-03 -3.3832e-02\n",
       " \n",
       " (0 ,9 ,.,.) = \n",
       "  -1.3496e-02 -6.1922e-02 -2.2780e-03 -6.2068e-02 -2.4017e-03\n",
       "  -5.1463e-02 -2.6216e-02 -3.3446e-02 -3.7419e-02 -5.1487e-02\n",
       "  -8.7326e-02 -4.6207e-02 -2.5539e-02 -5.7576e-03  4.0176e-02\n",
       "   2.7977e-03  3.8156e-02 -1.9934e-02 -4.9517e-02  3.2943e-02\n",
       "  -2.4588e-02  1.4552e-02  1.4208e-02 -6.4004e-02 -5.3016e-02\n",
       "      ⋮ \n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       "  -8.1942e-02 -5.8643e-02 -6.3911e-02 -9.9203e-02 -1.1042e-01\n",
       "   5.4047e-02  6.2637e-02  1.2800e-01  1.0550e-01  5.1798e-02\n",
       "   5.4208e-02  8.1553e-02  2.6328e-02  1.1554e-01  8.1066e-02\n",
       "  -1.0051e-01 -1.3629e-01 -3.5659e-02 -5.3209e-03  6.4804e-02\n",
       "  -1.2290e-02 -3.3916e-02 -6.1890e-02 -6.5692e-04 -6.1985e-02\n",
       " \n",
       " (1 ,1 ,.,.) = \n",
       "  -2.4181e-02 -9.9036e-03  7.9705e-04  4.1870e-02 -4.4398e-02\n",
       "   1.6604e-03  7.4159e-02  5.9477e-02  6.1576e-02 -2.4069e-02\n",
       "   3.7415e-02  8.2355e-02  1.2938e-02  6.8703e-02  9.7443e-02\n",
       "   3.8423e-02  3.0785e-02 -3.1419e-03 -1.0014e-02  7.4678e-02\n",
       "   2.9629e-03 -1.0107e-01 -1.0672e-01 -5.9425e-02 -4.5090e-02\n",
       " \n",
       " (1 ,2 ,.,.) = \n",
       "   9.1372e-03  4.2835e-02  5.1005e-02  7.3305e-03  3.6602e-02\n",
       "   5.7774e-02  1.2955e-01  1.9283e-01  1.2323e-01 -4.6549e-04\n",
       "  -4.3405e-03  3.3408e-03 -7.4054e-02 -2.1248e-02  5.3926e-02\n",
       "  -1.5822e-01 -1.3874e-01 -1.2333e-01 -6.0790e-02  6.3453e-02\n",
       "   9.3821e-02  1.4067e-01  9.2881e-03  1.1837e-03  6.7920e-03\n",
       "    ...\n",
       " \n",
       " (1 ,7 ,.,.) = \n",
       "  -3.4124e-02 -2.9526e-02 -1.4789e-02 -1.5520e-02 -4.8750e-02\n",
       "   5.0573e-02 -9.1277e-03  3.3697e-02  3.5776e-02 -9.4784e-02\n",
       "  -8.9592e-02 -1.3648e-01 -1.0386e-01 -4.3569e-04 -9.7912e-03\n",
       "  -1.3508e-01 -1.1009e-01 -9.0910e-02 -4.9593e-02  6.7420e-02\n",
       "  -4.1626e-02 -6.0964e-03  3.1860e-02 -4.2141e-03 -1.8201e-02\n",
       " \n",
       " (1 ,8 ,.,.) = \n",
       "  -3.7240e-02 -1.2342e-02  5.9027e-02  2.1134e-02  6.7772e-03\n",
       "   5.4383e-02  3.6877e-02  1.1131e-01  4.6943e-02  2.3132e-02\n",
       "   4.4748e-02  2.2736e-02  4.2088e-02  5.5120e-02 -3.3252e-03\n",
       "   1.4112e-02  5.4629e-02  9.8213e-03  8.9056e-03  1.6393e-02\n",
       "   1.0746e-01  3.3725e-02  1.0774e-01  6.8550e-02 -5.4841e-02\n",
       " \n",
       " (1 ,9 ,.,.) = \n",
       "   1.0574e-02 -8.9912e-02 -2.9300e-02 -2.9861e-02 -7.6725e-02\n",
       "   3.4195e-02  4.7692e-02  2.7471e-02 -1.7024e-02  3.3228e-02\n",
       "   4.1416e-02  7.4088e-02  2.6451e-02  9.2053e-02  2.0281e-03\n",
       "  -9.2598e-02  9.0705e-04 -3.7319e-02  5.9154e-04  7.5666e-02\n",
       "  -9.6487e-02 -1.0439e-01 -5.3283e-02 -1.5615e-02  6.6012e-02\n",
       "      ⋮ \n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       "   3.8963e-02  2.4092e-02  1.3375e-02 -2.4120e-02  8.1833e-02\n",
       "  -2.7653e-02  2.2021e-03  3.5285e-02 -2.1706e-02  1.0901e-01\n",
       "  -4.1618e-02 -1.2254e-03 -1.0072e-01  3.0174e-02  4.2665e-02\n",
       "  -1.6050e-02  8.5382e-03 -9.1903e-02 -1.1543e-02  3.4630e-02\n",
       "  -9.0622e-02 -5.4625e-02 -4.5792e-02 -3.4625e-02 -8.1712e-03\n",
       " \n",
       " (2 ,1 ,.,.) = \n",
       "   5.7618e-02  4.5334e-02  4.3371e-02  1.5354e-02  2.9968e-02\n",
       "   8.2125e-03  6.3543e-02  4.1300e-02  8.9867e-02 -1.0005e-02\n",
       "   6.0188e-02  1.4624e-02 -3.8739e-02 -3.9642e-02  3.7548e-02\n",
       "  -5.7361e-02 -3.0198e-02 -9.7548e-02 -6.2573e-02 -3.3855e-02\n",
       "  -8.7193e-02  2.3135e-03  5.5947e-03 -7.1379e-02  1.7864e-03\n",
       " \n",
       " (2 ,2 ,.,.) = \n",
       "   4.5837e-02 -3.4489e-02  2.2108e-02  8.5118e-02 -1.3556e-02\n",
       "  -5.5479e-02  7.7825e-03 -7.8942e-02  2.6550e-02 -2.0363e-02\n",
       "  -7.0713e-02 -7.3516e-02 -2.7017e-02 -6.2065e-02  4.1268e-02\n",
       "   1.8350e-02 -1.9440e-02  4.8501e-03 -4.2172e-02  5.8520e-02\n",
       "  -6.0815e-02 -1.7894e-02 -5.0678e-02  4.8741e-02 -5.7985e-02\n",
       "    ...\n",
       " \n",
       " (2 ,7 ,.,.) = \n",
       "  -3.1105e-02  5.6793e-02 -1.5133e-02  6.9682e-02 -2.9198e-02\n",
       "  -4.7690e-02  7.7932e-03  2.4458e-02 -2.0783e-02  5.0035e-02\n",
       "   1.2206e-02 -8.4984e-02 -5.0299e-02  7.2883e-03  8.9945e-02\n",
       "  -2.7077e-02 -5.0445e-02 -1.5866e-02  7.6839e-02  1.4516e-02\n",
       "  -5.4807e-02  2.8380e-02  1.0962e-01  9.0885e-02 -1.0226e-01\n",
       " \n",
       " (2 ,8 ,.,.) = \n",
       "   4.7285e-02  6.0047e-02 -2.3273e-02  1.7695e-02 -1.4036e-02\n",
       "  -4.2922e-02 -1.7499e-02  5.9314e-04  8.3099e-03 -3.1075e-02\n",
       "   2.9675e-02  1.3438e-02  3.5705e-02  6.9704e-03 -4.8885e-03\n",
       "   3.1202e-02 -5.4148e-03  6.8006e-02  2.1065e-02 -6.6606e-02\n",
       "  -5.6174e-02 -1.3653e-03  1.3865e-02 -2.1407e-02 -6.7061e-02\n",
       " \n",
       " (2 ,9 ,.,.) = \n",
       "   5.6230e-02 -3.6362e-02 -1.7386e-02 -6.1642e-02 -1.9436e-02\n",
       "  -9.3707e-03  4.8684e-02 -5.9519e-02  2.2402e-02  7.3215e-02\n",
       "   1.7669e-02 -5.0675e-02  1.3315e-05 -9.3748e-02  1.4194e-02\n",
       "   1.2506e-02 -7.4346e-02 -5.0047e-02 -3.3870e-02 -3.1165e-02\n",
       "  -5.5466e-02  1.8286e-02 -1.9917e-02  5.8626e-02 -2.5063e-02\n",
       " ...   \n",
       "      ⋮ \n",
       " \n",
       " (17,0 ,.,.) = \n",
       "  -1.0197e-01 -2.2995e-02 -7.7424e-02 -8.3269e-02 -3.1121e-02\n",
       "  -2.1518e-02 -6.5697e-02  1.0441e-02 -9.6803e-02 -7.4191e-02\n",
       "   5.8772e-02  1.5513e-01  1.0480e-02 -2.5562e-02 -4.0813e-02\n",
       "  -8.0926e-02  1.4426e-01  6.9312e-02  1.0310e-01  7.6063e-02\n",
       "  -1.5021e-01  2.5082e-03  6.7811e-03  4.0445e-02  7.0141e-03\n",
       " \n",
       " (17,1 ,.,.) = \n",
       "   7.1195e-03 -6.3424e-02 -6.4237e-02  6.8344e-02  7.3618e-02\n",
       "  -9.9111e-03 -1.4244e-02  3.0838e-02 -4.0781e-02 -1.4006e-02\n",
       "   3.3901e-02  4.7019e-02  8.6494e-02  4.6369e-02 -2.7420e-02\n",
       "   6.4852e-02  1.0765e-01  1.3619e-01  1.1944e-01 -3.3874e-02\n",
       "  -7.2425e-03 -2.5275e-02  6.0304e-02  3.5427e-02  1.3104e-02\n",
       " \n",
       " (17,2 ,.,.) = \n",
       "   2.9875e-02 -7.8419e-02 -1.0783e-01 -3.9457e-02  3.1460e-02\n",
       "   5.6769e-02  7.1786e-03  1.3819e-02  1.2470e-02  5.7143e-03\n",
       "   4.6251e-02  5.1359e-02  5.8889e-02  8.3715e-02 -2.7203e-02\n",
       "  -8.0303e-02  6.1370e-02  1.1654e-04  5.5541e-02  1.7481e-03\n",
       "  -9.7257e-02 -6.5037e-02 -3.6758e-02 -7.9895e-02 -1.1414e-02\n",
       "    ...\n",
       " \n",
       " (17,7 ,.,.) = \n",
       "   3.5149e-02 -8.1953e-03  8.7836e-03 -4.9695e-03  3.8436e-02\n",
       "  -1.8265e-03 -6.0052e-02 -3.2089e-02 -3.8841e-04 -5.9015e-02\n",
       "   1.3664e-02 -1.9299e-02  2.9387e-04 -1.1071e-02 -6.7834e-02\n",
       "  -3.3124e-02 -3.2694e-02 -3.4222e-02 -6.5023e-02  4.3562e-02\n",
       "  -1.3107e-01 -2.2728e-02 -8.7885e-02  4.1780e-02 -2.6368e-02\n",
       " \n",
       " (17,8 ,.,.) = \n",
       "  -1.8158e-03 -1.1870e-02 -3.3091e-02 -5.6132e-02  2.2756e-02\n",
       "   4.6093e-02  2.1613e-02  2.9564e-02  6.4914e-02  5.7482e-02\n",
       "   2.9997e-02  6.9538e-02  9.6109e-02  2.8404e-02 -1.6552e-02\n",
       "  -6.8049e-03  5.0336e-02  3.2460e-02  3.1197e-02  5.7058e-02\n",
       "  -9.1694e-03 -6.4472e-03  6.1660e-02  3.8320e-02 -3.8472e-02\n",
       " \n",
       " (17,9 ,.,.) = \n",
       "  -1.0742e-03  2.5132e-02 -2.1733e-02  4.5084e-02  2.3605e-03\n",
       "   4.9663e-02  3.3225e-02  4.2266e-02 -8.6892e-02  2.9739e-02\n",
       "   6.8438e-02 -1.0580e-02  7.1212e-02  4.4803e-02  5.3477e-03\n",
       "   2.2394e-03  9.9324e-02  1.1380e-01  4.0249e-02  6.8299e-02\n",
       "  -1.0003e-01 -1.0297e-01  3.2689e-02 -1.5499e-02 -2.5354e-03\n",
       "      ⋮ \n",
       " \n",
       " (18,0 ,.,.) = \n",
       "  -6.0449e-02 -1.1878e-01 -6.9183e-02  2.1464e-02  3.9715e-02\n",
       "  -2.2396e-02 -2.9966e-02 -6.1288e-02 -8.6592e-02 -1.9407e-02\n",
       "  -9.6881e-02 -5.7986e-02 -5.4720e-02  3.8694e-02 -2.6714e-02\n",
       "  -2.5600e-02 -7.5831e-02 -2.9634e-02  2.5173e-03 -3.3367e-02\n",
       "  -8.4449e-02 -4.5035e-02 -1.4771e-02 -1.7005e-02 -9.9115e-02\n",
       " \n",
       " (18,1 ,.,.) = \n",
       "   3.8434e-02  2.2819e-02 -5.5251e-02  2.7538e-02  1.0777e-02\n",
       "  -3.1974e-02 -2.0137e-02 -7.1316e-02 -2.9303e-02 -6.6147e-02\n",
       "  -5.2084e-02 -1.7227e-02 -6.3889e-02 -3.2523e-02  4.7593e-03\n",
       "  -3.3255e-02  4.4487e-02  2.7438e-02  1.3722e-02  8.3884e-03\n",
       "   4.6573e-02  2.5610e-02 -7.5855e-06 -1.1581e-02 -2.7823e-02\n",
       " \n",
       " (18,2 ,.,.) = \n",
       "  -2.2001e-02 -9.0782e-02 -4.0109e-02  4.7617e-02 -2.1731e-04\n",
       "  -4.2581e-02  2.0243e-02  3.7345e-02  6.1281e-02  4.1842e-02\n",
       "  -3.7542e-02  9.7704e-03 -1.4155e-02 -5.1803e-03 -5.1615e-03\n",
       "   8.7871e-03  4.8908e-02  9.1002e-02  3.0552e-02  4.5431e-02\n",
       "  -9.3149e-02 -5.4033e-02  2.3358e-02 -7.1510e-02 -5.2667e-02\n",
       "    ...\n",
       " \n",
       " (18,7 ,.,.) = \n",
       "  -8.7114e-03 -8.0702e-02 -6.1187e-02  6.6869e-02  1.1244e-01\n",
       "  -8.6928e-02 -5.6073e-02  8.2770e-02  1.3519e-01 -4.9767e-02\n",
       "  -1.8240e-02  1.9869e-02  4.8168e-02  6.3492e-02 -1.4513e-02\n",
       "   1.4105e-02  7.1468e-02 -7.0865e-04 -4.9006e-02 -7.3991e-02\n",
       "   3.1146e-02  9.2861e-02 -4.3075e-02 -9.6326e-02 -5.9501e-02\n",
       " \n",
       " (18,8 ,.,.) = \n",
       "  -6.1665e-02  3.4716e-02 -2.8896e-02 -1.3364e-02 -1.6774e-03\n",
       "  -1.5041e-02  5.1352e-02  4.6352e-02 -4.3312e-02 -1.0827e-02\n",
       "   1.7429e-02  3.9333e-02  2.1591e-02  3.1762e-02 -1.2595e-02\n",
       "   2.7801e-02 -2.7519e-02 -1.4918e-02 -3.6845e-02 -3.6475e-02\n",
       "   9.3258e-03 -1.8331e-02 -2.8897e-02 -6.6888e-02  4.8788e-02\n",
       " \n",
       " (18,9 ,.,.) = \n",
       "  -4.9851e-02 -3.9608e-02 -8.0639e-02 -4.6388e-02  2.0321e-02\n",
       "  -2.1772e-02 -1.0359e-01 -4.5907e-02 -8.2712e-02 -6.7920e-02\n",
       "  -1.0102e-03 -7.6569e-02  5.4759e-02 -6.2198e-02  2.5138e-02\n",
       "  -2.3732e-02  1.3329e-02 -3.0017e-02  4.6059e-02  2.4270e-02\n",
       "   7.4213e-02 -2.9617e-04 -4.0721e-02  2.7932e-03  2.2503e-02\n",
       "      ⋮ \n",
       " \n",
       " (19,0 ,.,.) = \n",
       "   3.3122e-02 -2.3315e-02 -2.7450e-02 -4.3275e-02  9.9985e-02\n",
       "   5.2682e-02  1.0100e-03 -1.2654e-01 -2.9379e-02 -9.0482e-03\n",
       "   2.8147e-03  1.5471e-01  4.7444e-02 -1.5515e-02  1.7949e-02\n",
       "  -1.7974e-02  9.9845e-02  1.7738e-01  1.4221e-01  4.3737e-02\n",
       "   3.4032e-03  8.8568e-02  3.9112e-02  4.1876e-02  4.9972e-03\n",
       " \n",
       " (19,1 ,.,.) = \n",
       "  -3.3582e-02 -1.8600e-02  3.0146e-02 -2.2848e-03  5.7631e-02\n",
       "  -2.4887e-02  1.2412e-02 -2.8446e-02 -2.3516e-02  7.3764e-02\n",
       "   5.3093e-02  1.1196e-01 -2.4563e-02 -3.8623e-02 -7.0587e-02\n",
       "   2.5031e-02  1.2668e-01  9.8788e-02  8.1837e-03  1.9535e-02\n",
       "  -3.5163e-02 -2.0059e-02 -3.8169e-02  7.0664e-02  6.8745e-02\n",
       " \n",
       " (19,2 ,.,.) = \n",
       "  -6.6434e-03 -2.2980e-02 -6.7729e-02 -3.7103e-03 -3.1294e-02\n",
       "   3.6863e-02 -3.3596e-03 -2.8174e-02 -1.1299e-01 -1.2318e-02\n",
       "  -1.5668e-03  1.1454e-01  5.0502e-02  1.7587e-03 -2.3989e-02\n",
       "  -2.9470e-02  5.4826e-02  3.7800e-02  7.5996e-02  6.2941e-02\n",
       "  -8.7302e-02 -3.9045e-03 -5.3019e-02  2.3020e-02 -1.0556e-01\n",
       "    ...\n",
       " \n",
       " (19,7 ,.,.) = \n",
       "  -3.6926e-02 -6.9153e-02 -1.2482e-02  1.1639e-02 -1.2527e-02\n",
       "   1.8725e-02  6.0959e-02 -8.4907e-02 -8.1778e-02 -4.3081e-02\n",
       "   3.6566e-02 -7.5934e-02 -7.6092e-02 -7.2351e-02 -3.7865e-02\n",
       "   2.9871e-02  3.0657e-02  4.4996e-02  5.0765e-02 -3.6923e-02\n",
       "  -9.5962e-02  4.9069e-03 -3.1250e-02 -6.7285e-02 -4.9669e-02\n",
       " \n",
       " (19,8 ,.,.) = \n",
       "  -5.4333e-02 -2.9830e-03 -8.7737e-03  1.7792e-02  2.3232e-02\n",
       "   3.7248e-03  9.1955e-02 -1.2003e-02 -4.0891e-02 -4.3087e-02\n",
       "   1.6054e-02 -3.8519e-02 -2.0774e-02  8.0969e-02 -3.2495e-02\n",
       "  -4.9099e-03 -1.8565e-02  1.6973e-02 -4.2003e-02  3.9286e-02\n",
       "   2.2510e-02  4.7421e-02  4.8580e-02  1.3529e-02  2.9826e-02\n",
       " \n",
       " (19,9 ,.,.) = \n",
       "  -3.9611e-02 -5.1517e-02 -9.1571e-02  1.5929e-02  4.1393e-02\n",
       "  -4.6854e-02  4.6607e-02  2.9328e-02 -1.0111e-03 -1.0746e-02\n",
       "  -4.5147e-02  2.0799e-02  4.9559e-02  2.3412e-02 -8.6379e-02\n",
       "  -9.7175e-02 -1.0794e-02  1.2169e-01 -6.3197e-03  2.0450e-02\n",
       "  -9.1908e-02 -2.2905e-02 -2.3070e-02  4.9691e-02  5.7804e-02\n",
       " [torch.FloatTensor of size 20x10x5x5], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "   2.4103\n",
       "   2.2232\n",
       "   2.3224\n",
       "   3.2518\n",
       "  -4.2167\n",
       "  -6.2022\n",
       "   2.6381\n",
       "   0.0702\n",
       "   4.8453\n",
       "  -3.1157\n",
       "  -5.2136\n",
       "   6.9174\n",
       "  -0.4145\n",
       "   2.3497\n",
       "  -5.2485\n",
       "  -2.5922\n",
       "  -6.3356\n",
       "   4.3994\n",
       "  -0.1977\n",
       "   6.0233\n",
       " [torch.FloatTensor of size 20], Parameter containing:\n",
       " -1.3847e-03  1.2418e-02 -4.1320e-02  ...   5.8005e-02 -5.0558e-02  4.3361e-02\n",
       "  2.3902e-02 -4.8468e-02  6.0686e-03  ...   6.7830e-03 -2.6844e-02  3.1665e-02\n",
       "  1.9037e-02  3.5444e-02  5.2060e-02  ...   1.0132e-02  3.4025e-02 -1.7027e-02\n",
       "                 ...                   ⋱                   ...                \n",
       " -1.1197e-02  9.4759e-03 -3.4992e-03  ...  -2.9874e-03 -1.5373e-02 -4.2577e-03\n",
       "  3.8235e-02  4.4457e-02  1.3205e-02  ...   1.0407e-01  5.5560e-03 -3.1458e-02\n",
       "  3.7971e-02  8.6876e-02  6.0070e-02  ...   8.2687e-02  7.1484e-03 -2.5846e-02\n",
       " [torch.FloatTensor of size 50x320], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "   3.9259\n",
       "  -2.7801\n",
       "   5.9484\n",
       "   0.3870\n",
       "   0.0654\n",
       "   0.4366\n",
       "  -3.8175\n",
       "  -5.2667\n",
       "   3.1918\n",
       "  -2.8017\n",
       "   0.9092\n",
       "  -3.3857\n",
       "   6.1078\n",
       "   0.9712\n",
       "   6.9119\n",
       "   4.1210\n",
       "   4.8603\n",
       "  -0.7278\n",
       "  -0.2234\n",
       "  -0.5233\n",
       "   6.0273\n",
       "   4.7747\n",
       "   4.2506\n",
       "  -4.6518\n",
       "   2.6726\n",
       "  -0.4177\n",
       "   6.2178\n",
       "   2.6575\n",
       "   6.6797\n",
       "   6.1835\n",
       "  -2.5790\n",
       "   1.2465\n",
       "   0.3375\n",
       "   2.6311\n",
       "   7.5150\n",
       "   3.0269\n",
       "   6.5540\n",
       "   3.4880\n",
       "   6.0364\n",
       "   4.7539\n",
       "   5.9535\n",
       "  -3.6503\n",
       "   4.0583\n",
       "   4.9907\n",
       "  -3.3656\n",
       "   3.3834\n",
       "   3.0907\n",
       "  -1.2063\n",
       "   3.7742\n",
       "   1.6067\n",
       " [torch.FloatTensor of size 50], Parameter containing:\n",
       " \n",
       " Columns 0 to 9 \n",
       "  0.1477  0.1018  0.1016 -0.0382  0.1128  0.1965 -0.0506 -0.0964  0.0836 -0.2016\n",
       " -0.1293  0.1281  0.0370  0.3567 -0.2005 -0.1840 -0.1748 -0.0572  0.0549  0.1659\n",
       "  0.1997 -0.1053  0.1600 -0.0552 -0.0826  0.2001  0.1377 -0.0333 -0.2012 -0.0510\n",
       "  0.1100 -0.0330  0.1487  0.0739 -0.0973 -0.0912  0.1785  0.0991 -0.1605 -0.1838\n",
       " -0.1333  0.0128 -0.2240  0.0585  0.1387 -0.1278 -0.0394  0.1602  0.0579  0.1377\n",
       " -0.1413 -0.0242  0.0982  0.0677  0.1842 -0.0615  0.1171 -0.0180  0.1870 -0.1211\n",
       "  0.0372  0.0738  0.1180 -0.0735 -0.0238  0.0645 -0.1982 -0.1309  0.1674  0.1320\n",
       "  0.1310 -0.0541 -0.0646 -0.0807 -0.0420  0.1885 -0.0405 -0.0387 -0.1094 -0.1513\n",
       "  0.1259 -0.0311  0.1541 -0.0009 -0.0785  0.0203 -0.0398  0.0255  0.1484  0.1100\n",
       " -0.1684 -0.0412 -0.1358 -0.0772 -0.0268 -0.0342  0.1434  0.1218 -0.1373  0.0223\n",
       " \n",
       " Columns 10 to 19 \n",
       " -0.1136  0.2126 -0.1308 -0.2112  0.0963 -0.1730  0.1947  0.0949 -0.0508 -0.2381\n",
       "  0.0325 -0.0980  0.2016  0.1509 -0.0673 -0.0402 -0.0439 -0.2264  0.1787 -0.2182\n",
       " -0.2017 -0.0355 -0.1082  0.1017 -0.2163  0.2353 -0.0243  0.0549  0.1908 -0.1015\n",
       " -0.0964  0.0317 -0.0928  0.1830  0.1415  0.0986  0.0663  0.0973 -0.0015  0.1273\n",
       "  0.1184 -0.0783  0.1238 -0.1530 -0.0932 -0.0871 -0.0027 -0.2409  0.1527  0.0047\n",
       "  0.1510  0.0067 -0.0099  0.1092  0.1879 -0.1695 -0.0190  0.0267 -0.1364  0.1082\n",
       "  0.1586 -0.1355 -0.1967  0.1296  0.0998 -0.0612 -0.1320 -0.2738  0.1418 -0.0848\n",
       "  0.0996  0.1568  0.2472 -0.1250  0.1419  0.2132  0.2175  0.1145  0.1516 -0.0674\n",
       " -0.1647 -0.0370 -0.1450  0.0138 -0.1238 -0.0366 -0.0785 -0.0324  0.0356  0.0781\n",
       "  0.1094  0.2124  0.1955 -0.1873 -0.0722 -0.0492  0.0701  0.1082 -0.1293  0.0235\n",
       " \n",
       " Columns 20 to 29 \n",
       "  0.1310  0.0380 -0.2520 -0.0738  0.1217  0.2162  0.2040 -0.0424  0.1010 -0.2357\n",
       " -0.2172 -0.0729  0.0824 -0.0110 -0.1400 -0.0971  0.1895 -0.0258  0.1314  0.1775\n",
       " -0.0480  0.1366 -0.0286 -0.1480 -0.1624  0.0439  0.2019  0.0006  0.1049  0.1517\n",
       "  0.0275 -0.1279  0.0874  0.1821 -0.1721 -0.1114  0.0692 -0.1311  0.1232 -0.1766\n",
       " -0.2504  0.1282  0.0780  0.0920  0.0598  0.0857 -0.1250  0.2554 -0.1195 -0.0429\n",
       "  0.1456 -0.0726 -0.1765  0.0785 -0.0621  0.0682 -0.1061 -0.0115  0.1326 -0.0830\n",
       "  0.1196  0.1000 -0.2938 -0.2347  0.0862  0.0122 -0.1044  0.2667  0.1005  0.1520\n",
       " -0.1366 -0.1982  0.0198  0.1633 -0.0939 -0.0719  0.1876 -0.0432 -0.2152 -0.1059\n",
       "  0.1516  0.1746  0.1255 -0.1099 -0.1317 -0.0417 -0.0131 -0.0558  0.0938 -0.1319\n",
       " -0.0690  0.0947  0.0874  0.1593  0.2110 -0.1100 -0.1883 -0.1983 -0.1481 -0.1897\n",
       " \n",
       " Columns 30 to 39 \n",
       "  0.1129 -0.1700 -0.0056  0.0825 -0.2435  0.0322  0.0218 -0.1898  0.0396 -0.0905\n",
       "  0.1072 -0.1882  0.0207 -0.2847  0.1271 -0.2363  0.2028 -0.1954  0.1954 -0.1541\n",
       " -0.0445  0.1098 -0.0297 -0.1985  0.0764 -0.0102  0.0057 -0.2059  0.1438 -0.1660\n",
       "  0.1278 -0.1270  0.0222 -0.1973  0.1450 -0.0614 -0.1073  0.1303 -0.1172  0.0050\n",
       " -0.2203  0.1141 -0.0359  0.0999  0.1579  0.1856  0.2042 -0.1683  0.0198  0.1705\n",
       "  0.1243  0.1347 -0.0723  0.0462  0.0450  0.0774 -0.1446  0.1520 -0.0573 -0.1598\n",
       " -0.1253 -0.1640  0.3062  0.1212 -0.2669  0.1517 -0.0365 -0.0734 -0.1157 -0.1061\n",
       "  0.0637 -0.1031  0.0462  0.0567  0.1387 -0.1925  0.1481 -0.2531  0.2095  0.2210\n",
       " -0.1588 -0.1511  0.0549 -0.0906  0.1119 -0.1254  0.1723  0.1298 -0.1688 -0.1125\n",
       " -0.0485  0.1330  0.0478  0.0325  0.1440  0.1160  0.1526  0.0511  0.0119  0.1511\n",
       " \n",
       " Columns 40 to 49 \n",
       " -0.0246 -0.0631  0.1916 -0.1842 -0.0315 -0.1910 -0.0694 -0.2658  0.1493  0.1994\n",
       "  0.1087 -0.0739 -0.1404  0.1753 -0.0435  0.0732  0.1269  0.0536 -0.2302 -0.0500\n",
       "  0.0565  0.1978  0.1646  0.2250 -0.1451  0.1308 -0.0135 -0.1590  0.1432 -0.0844\n",
       "  0.0158  0.0386  0.1570  0.2082 -0.1325  0.0136  0.1777 -0.0092 -0.1474 -0.0620\n",
       " -0.1090  0.2367  0.0126 -0.1231  0.0712 -0.1322 -0.2049  0.1073  0.0124 -0.0258\n",
       "  0.2095  0.0023 -0.1747 -0.1388 -0.1343 -0.2219 -0.0892  0.1264  0.0110  0.1721\n",
       " -0.0857  0.2039 -0.1134 -0.0392  0.0014 -0.1681 -0.1337 -0.2350  0.1297  0.1849\n",
       "  0.1149 -0.0979 -0.0415  0.0182 -0.1485  0.1330  0.0313  0.1078 -0.2219 -0.2123\n",
       "  0.2252 -0.0951 -0.1139 -0.0991  0.0537  0.1619  0.1546  0.1003  0.1167  0.2019\n",
       "  0.1620 -0.1542  0.0570 -0.1612 -0.0106  0.1323 -0.1010  0.1257  0.0457 -0.1273\n",
       " [torch.FloatTensor of size 10x50], Parameter containing:\n",
       " -0.0827\n",
       "  0.1294\n",
       " -0.0102\n",
       "  0.0677\n",
       " -0.1396\n",
       " -0.0263\n",
       " -0.1230\n",
       " -0.1337\n",
       "  0.1562\n",
       "  0.1280\n",
       " [torch.FloatTensor of size 10]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = model.parameters()\n",
    "list(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model,\"./mnist.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.load(\"./mnist.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  0.2128  0.2661  0.2396 -0.1836 -0.3214\n",
      "  0.0157  0.1445  0.2532 -0.0322 -0.2574\n",
      " -0.0198  0.0518  0.3674  0.1567 -0.0764\n",
      " -0.2078 -0.0753  0.3650  0.3314  0.3167\n",
      "  0.0271  0.0753  0.2105  0.1834  0.0159\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      "  0.0091 -0.0887  0.2363 -0.0788 -0.0898\n",
      "  0.1534  0.1306  0.2471  0.2930 -0.0520\n",
      " -0.1567 -0.1610  0.1837  0.1065  0.1585\n",
      "  0.0767 -0.0614 -0.1659  0.1720  0.0434\n",
      " -0.3042 -0.2339 -0.0299 -0.2120  0.1300\n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      " -0.1439  0.1628  0.0856 -0.0226 -0.1260\n",
      " -0.1116 -0.0772  0.2109  0.0476 -0.2457\n",
      " -0.1226  0.0633  0.1716  0.1777 -0.2553\n",
      " -0.0661  0.0993  0.1912  0.2740  0.2219\n",
      "  0.2091  0.2903  0.2456  0.4195  0.4125\n",
      "\n",
      "(3 ,0 ,.,.) = \n",
      " -0.0737  0.0990 -0.2314 -0.1565  0.2563\n",
      " -0.1747 -0.0674 -0.2561  0.1521  0.2682\n",
      " -0.1640 -0.0754 -0.1645  0.1075  0.2138\n",
      "  0.0290  0.0320 -0.1092 -0.0362  0.2153\n",
      " -0.1576 -0.0551 -0.0627  0.2720  0.0777\n",
      "\n",
      "(4 ,0 ,.,.) = \n",
      "  0.2749  0.1944 -0.1642 -0.1272 -0.1396\n",
      "  0.2183 -0.0365 -0.2747 -0.2110  0.1612\n",
      "  0.1247 -0.0256 -0.0554  0.2436  0.2308\n",
      "  0.1862  0.1427  0.0715  0.0820  0.2831\n",
      " -0.0634 -0.1533 -0.0731  0.1023  0.0338\n",
      "\n",
      "(5 ,0 ,.,.) = \n",
      " -0.1508 -0.1158 -0.0891 -0.2971 -0.1980\n",
      " -0.0848 -0.2057 -0.1477 -0.2028  0.1333\n",
      " -0.1802 -0.1165 -0.0720 -0.1605  0.2590\n",
      " -0.1247 -0.0492 -0.1875  0.1395  0.1957\n",
      " -0.0752 -0.0601 -0.0150  0.2703  0.2265\n",
      "\n",
      "(6 ,0 ,.,.) = \n",
      " -0.0631  0.1823 -0.0714  0.1108 -0.1504\n",
      " -0.1046 -0.1651 -0.1279  0.2267  0.0727\n",
      "  0.0866 -0.0946 -0.1843  0.0547 -0.0425\n",
      " -0.1937  0.0140  0.1033 -0.1091 -0.0951\n",
      " -0.0115 -0.2019 -0.2121 -0.1127 -0.0479\n",
      "\n",
      "(7 ,0 ,.,.) = \n",
      " -0.0718 -0.2162  0.1387  0.1459  0.2444\n",
      " -0.1471 -0.0514  0.1238 -0.0165  0.3950\n",
      " -0.2738 -0.0149 -0.0195  0.3147  0.1650\n",
      " -0.1093  0.0891  0.1053  0.5058  0.2993\n",
      "  0.0764  0.3043  0.2321  0.2654  0.1887\n",
      "\n",
      "(8 ,0 ,.,.) = \n",
      " -0.1175  0.1275  0.0757 -0.1335  0.0019\n",
      " -0.0526 -0.0913 -0.2381 -0.2459 -0.0273\n",
      " -0.0916  0.0490 -0.2299 -0.0171 -0.0429\n",
      "  0.1026  0.0308 -0.0228  0.1651 -0.1342\n",
      " -0.0642  0.1853  0.2888  0.3142  0.0129\n",
      "\n",
      "(9 ,0 ,.,.) = \n",
      "  0.1522  0.2451 -0.1192  0.0113  0.1628\n",
      "  0.3287  0.0562  0.3097  0.0714 -0.1256\n",
      " -0.0056 -0.0050  0.3163  0.1875  0.0795\n",
      "  0.1045 -0.1210  0.0380  0.2664  0.0127\n",
      " -0.0595 -0.0271 -0.0128 -0.1908  0.1512\n",
      "[torch.FloatTensor of size 10x1x5x5]\n",
      ", Parameter containing:\n",
      "-0.0032\n",
      " 0.0022\n",
      " 0.1817\n",
      " 0.1100\n",
      " 0.1303\n",
      " 0.2305\n",
      "-0.0542\n",
      " 0.0057\n",
      " 0.0252\n",
      " 0.1997\n",
      "[torch.FloatTensor of size 10]\n",
      ", Parameter containing:\n",
      "(0 ,0 ,.,.) = \n",
      " -7.7652e-02  3.4614e-02 -8.8260e-02 -3.0657e-02  1.1410e-02\n",
      " -5.1895e-02  7.3741e-02 -3.6333e-02  2.7281e-03 -6.3035e-02\n",
      "  1.7873e-03  2.4663e-02 -6.6437e-02 -1.0187e-01 -3.4793e-02\n",
      "  1.8305e-02 -8.2180e-02 -3.9401e-02 -7.4846e-02 -3.5981e-02\n",
      "  1.9486e-02  6.1374e-02 -1.7642e-02 -2.2890e-03 -3.3710e-02\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "  5.5989e-02  5.6606e-02 -2.3458e-02 -1.2595e-02 -5.3017e-02\n",
      " -6.1963e-02 -3.7892e-04 -2.6983e-02 -5.3699e-02 -4.0574e-02\n",
      "  1.6646e-02 -1.0174e-02 -8.9954e-02 -7.8483e-02 -1.9509e-02\n",
      " -4.1603e-02 -2.3816e-03 -2.6562e-02  2.4484e-02  4.7991e-02\n",
      " -5.5400e-02 -4.1052e-02 -4.2244e-03  3.6213e-02  1.0086e-02\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      " -8.5429e-02  8.0423e-02  2.3636e-02 -6.9460e-02 -1.5315e-02\n",
      " -7.7678e-03  7.2859e-02 -3.6987e-02 -1.2522e-02 -4.5186e-02\n",
      " -1.0504e-02  1.1947e-02 -1.0175e-01  5.1345e-03  4.4382e-02\n",
      " -2.8208e-02  5.2093e-03 -9.0747e-02 -5.5209e-03 -1.9305e-02\n",
      "  7.0401e-02 -3.5077e-02  4.7990e-02  6.6198e-02 -5.9677e-02\n",
      "   ...\n",
      "\n",
      "(0 ,7 ,.,.) = \n",
      "  4.3575e-02  9.8056e-02  7.5455e-02 -8.5456e-02  4.2197e-02\n",
      "  7.8533e-02  8.3034e-02  4.1399e-02  6.1599e-03  5.6505e-02\n",
      "  6.3450e-02  9.5853e-02 -5.1113e-02 -6.0634e-02  4.3138e-03\n",
      "  3.1584e-02  4.1255e-03 -4.2028e-02 -3.7523e-02 -3.0928e-02\n",
      "  3.9368e-02 -7.3634e-02 -4.0086e-02  3.6493e-02  1.5962e-02\n",
      "\n",
      "(0 ,8 ,.,.) = \n",
      "  1.3383e-02 -5.1415e-02 -1.3833e-02  6.5372e-03 -7.8979e-03\n",
      " -2.7645e-02  6.1129e-03 -2.4996e-02  3.9922e-02  2.2022e-03\n",
      " -2.9684e-02 -3.1802e-02 -2.8030e-02  3.4757e-02  5.6568e-02\n",
      " -6.9756e-02 -6.6191e-02 -1.2072e-02  5.0716e-02  1.3553e-02\n",
      " -4.0526e-02 -2.3764e-03  3.4656e-02  7.9143e-03 -3.3832e-02\n",
      "\n",
      "(0 ,9 ,.,.) = \n",
      " -1.3496e-02 -6.1922e-02 -2.2780e-03 -6.2068e-02 -2.4017e-03\n",
      " -5.1463e-02 -2.6216e-02 -3.3446e-02 -3.7419e-02 -5.1487e-02\n",
      " -8.7326e-02 -4.6207e-02 -2.5539e-02 -5.7576e-03  4.0176e-02\n",
      "  2.7977e-03  3.8156e-02 -1.9934e-02 -4.9517e-02  3.2943e-02\n",
      " -2.4588e-02  1.4552e-02  1.4208e-02 -6.4004e-02 -5.3016e-02\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -8.1942e-02 -5.8643e-02 -6.3911e-02 -9.9203e-02 -1.1042e-01\n",
      "  5.4047e-02  6.2637e-02  1.2800e-01  1.0550e-01  5.1798e-02\n",
      "  5.4208e-02  8.1553e-02  2.6328e-02  1.1554e-01  8.1066e-02\n",
      " -1.0051e-01 -1.3629e-01 -3.5659e-02 -5.3209e-03  6.4804e-02\n",
      " -1.2290e-02 -3.3916e-02 -6.1890e-02 -6.5692e-04 -6.1985e-02\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      " -2.4181e-02 -9.9036e-03  7.9705e-04  4.1870e-02 -4.4398e-02\n",
      "  1.6604e-03  7.4159e-02  5.9477e-02  6.1576e-02 -2.4069e-02\n",
      "  3.7415e-02  8.2355e-02  1.2938e-02  6.8703e-02  9.7443e-02\n",
      "  3.8423e-02  3.0785e-02 -3.1419e-03 -1.0014e-02  7.4678e-02\n",
      "  2.9629e-03 -1.0107e-01 -1.0672e-01 -5.9425e-02 -4.5090e-02\n",
      "\n",
      "(1 ,2 ,.,.) = \n",
      "  9.1372e-03  4.2835e-02  5.1005e-02  7.3305e-03  3.6602e-02\n",
      "  5.7774e-02  1.2955e-01  1.9283e-01  1.2323e-01 -4.6549e-04\n",
      " -4.3405e-03  3.3408e-03 -7.4054e-02 -2.1248e-02  5.3926e-02\n",
      " -1.5822e-01 -1.3874e-01 -1.2333e-01 -6.0790e-02  6.3453e-02\n",
      "  9.3821e-02  1.4067e-01  9.2881e-03  1.1837e-03  6.7920e-03\n",
      "   ...\n",
      "\n",
      "(1 ,7 ,.,.) = \n",
      " -3.4124e-02 -2.9526e-02 -1.4789e-02 -1.5520e-02 -4.8750e-02\n",
      "  5.0573e-02 -9.1277e-03  3.3697e-02  3.5776e-02 -9.4784e-02\n",
      " -8.9592e-02 -1.3648e-01 -1.0386e-01 -4.3569e-04 -9.7912e-03\n",
      " -1.3508e-01 -1.1009e-01 -9.0910e-02 -4.9593e-02  6.7420e-02\n",
      " -4.1626e-02 -6.0964e-03  3.1860e-02 -4.2141e-03 -1.8201e-02\n",
      "\n",
      "(1 ,8 ,.,.) = \n",
      " -3.7240e-02 -1.2342e-02  5.9027e-02  2.1134e-02  6.7772e-03\n",
      "  5.4383e-02  3.6877e-02  1.1131e-01  4.6943e-02  2.3132e-02\n",
      "  4.4748e-02  2.2736e-02  4.2088e-02  5.5120e-02 -3.3252e-03\n",
      "  1.4112e-02  5.4629e-02  9.8213e-03  8.9056e-03  1.6393e-02\n",
      "  1.0746e-01  3.3725e-02  1.0774e-01  6.8550e-02 -5.4841e-02\n",
      "\n",
      "(1 ,9 ,.,.) = \n",
      "  1.0574e-02 -8.9912e-02 -2.9300e-02 -2.9861e-02 -7.6725e-02\n",
      "  3.4195e-02  4.7692e-02  2.7471e-02 -1.7024e-02  3.3228e-02\n",
      "  4.1416e-02  7.4088e-02  2.6451e-02  9.2053e-02  2.0281e-03\n",
      " -9.2598e-02  9.0705e-04 -3.7319e-02  5.9154e-04  7.5666e-02\n",
      " -9.6487e-02 -1.0439e-01 -5.3283e-02 -1.5615e-02  6.6012e-02\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      "  3.8963e-02  2.4092e-02  1.3375e-02 -2.4120e-02  8.1833e-02\n",
      " -2.7653e-02  2.2021e-03  3.5285e-02 -2.1706e-02  1.0901e-01\n",
      " -4.1618e-02 -1.2254e-03 -1.0072e-01  3.0174e-02  4.2665e-02\n",
      " -1.6050e-02  8.5382e-03 -9.1903e-02 -1.1543e-02  3.4630e-02\n",
      " -9.0622e-02 -5.4625e-02 -4.5792e-02 -3.4625e-02 -8.1712e-03\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      "  5.7618e-02  4.5334e-02  4.3371e-02  1.5354e-02  2.9968e-02\n",
      "  8.2125e-03  6.3543e-02  4.1300e-02  8.9867e-02 -1.0005e-02\n",
      "  6.0188e-02  1.4624e-02 -3.8739e-02 -3.9642e-02  3.7548e-02\n",
      " -5.7361e-02 -3.0198e-02 -9.7548e-02 -6.2573e-02 -3.3855e-02\n",
      " -8.7193e-02  2.3135e-03  5.5947e-03 -7.1379e-02  1.7864e-03\n",
      "\n",
      "(2 ,2 ,.,.) = \n",
      "  4.5837e-02 -3.4489e-02  2.2108e-02  8.5118e-02 -1.3556e-02\n",
      " -5.5479e-02  7.7825e-03 -7.8942e-02  2.6550e-02 -2.0363e-02\n",
      " -7.0713e-02 -7.3516e-02 -2.7017e-02 -6.2065e-02  4.1268e-02\n",
      "  1.8350e-02 -1.9440e-02  4.8501e-03 -4.2172e-02  5.8520e-02\n",
      " -6.0815e-02 -1.7894e-02 -5.0678e-02  4.8741e-02 -5.7985e-02\n",
      "   ...\n",
      "\n",
      "(2 ,7 ,.,.) = \n",
      " -3.1105e-02  5.6793e-02 -1.5133e-02  6.9682e-02 -2.9198e-02\n",
      " -4.7690e-02  7.7932e-03  2.4458e-02 -2.0783e-02  5.0035e-02\n",
      "  1.2206e-02 -8.4984e-02 -5.0299e-02  7.2883e-03  8.9945e-02\n",
      " -2.7077e-02 -5.0445e-02 -1.5866e-02  7.6839e-02  1.4516e-02\n",
      " -5.4807e-02  2.8380e-02  1.0962e-01  9.0885e-02 -1.0226e-01\n",
      "\n",
      "(2 ,8 ,.,.) = \n",
      "  4.7285e-02  6.0047e-02 -2.3273e-02  1.7695e-02 -1.4036e-02\n",
      " -4.2922e-02 -1.7499e-02  5.9314e-04  8.3099e-03 -3.1075e-02\n",
      "  2.9675e-02  1.3438e-02  3.5705e-02  6.9704e-03 -4.8885e-03\n",
      "  3.1202e-02 -5.4148e-03  6.8006e-02  2.1065e-02 -6.6606e-02\n",
      " -5.6174e-02 -1.3653e-03  1.3865e-02 -2.1407e-02 -6.7061e-02\n",
      "\n",
      "(2 ,9 ,.,.) = \n",
      "  5.6230e-02 -3.6362e-02 -1.7386e-02 -6.1642e-02 -1.9436e-02\n",
      " -9.3707e-03  4.8684e-02 -5.9519e-02  2.2402e-02  7.3215e-02\n",
      "  1.7669e-02 -5.0675e-02  1.3315e-05 -9.3748e-02  1.4194e-02\n",
      "  1.2506e-02 -7.4346e-02 -5.0047e-02 -3.3870e-02 -3.1165e-02\n",
      " -5.5466e-02  1.8286e-02 -1.9917e-02  5.8626e-02 -2.5063e-02\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(17,0 ,.,.) = \n",
      " -1.0197e-01 -2.2995e-02 -7.7424e-02 -8.3269e-02 -3.1121e-02\n",
      " -2.1518e-02 -6.5697e-02  1.0441e-02 -9.6803e-02 -7.4191e-02\n",
      "  5.8772e-02  1.5513e-01  1.0480e-02 -2.5562e-02 -4.0813e-02\n",
      " -8.0926e-02  1.4426e-01  6.9312e-02  1.0310e-01  7.6063e-02\n",
      " -1.5021e-01  2.5082e-03  6.7811e-03  4.0445e-02  7.0141e-03\n",
      "\n",
      "(17,1 ,.,.) = \n",
      "  7.1195e-03 -6.3424e-02 -6.4237e-02  6.8344e-02  7.3618e-02\n",
      " -9.9111e-03 -1.4244e-02  3.0838e-02 -4.0781e-02 -1.4006e-02\n",
      "  3.3901e-02  4.7019e-02  8.6494e-02  4.6369e-02 -2.7420e-02\n",
      "  6.4852e-02  1.0765e-01  1.3619e-01  1.1944e-01 -3.3874e-02\n",
      " -7.2425e-03 -2.5275e-02  6.0304e-02  3.5427e-02  1.3104e-02\n",
      "\n",
      "(17,2 ,.,.) = \n",
      "  2.9875e-02 -7.8419e-02 -1.0783e-01 -3.9457e-02  3.1460e-02\n",
      "  5.6769e-02  7.1786e-03  1.3819e-02  1.2470e-02  5.7143e-03\n",
      "  4.6251e-02  5.1359e-02  5.8889e-02  8.3715e-02 -2.7203e-02\n",
      " -8.0303e-02  6.1370e-02  1.1654e-04  5.5541e-02  1.7481e-03\n",
      " -9.7257e-02 -6.5037e-02 -3.6758e-02 -7.9895e-02 -1.1414e-02\n",
      "   ...\n",
      "\n",
      "(17,7 ,.,.) = \n",
      "  3.5149e-02 -8.1953e-03  8.7836e-03 -4.9695e-03  3.8436e-02\n",
      " -1.8265e-03 -6.0052e-02 -3.2089e-02 -3.8841e-04 -5.9015e-02\n",
      "  1.3664e-02 -1.9299e-02  2.9387e-04 -1.1071e-02 -6.7834e-02\n",
      " -3.3124e-02 -3.2694e-02 -3.4222e-02 -6.5023e-02  4.3562e-02\n",
      " -1.3107e-01 -2.2728e-02 -8.7885e-02  4.1780e-02 -2.6368e-02\n",
      "\n",
      "(17,8 ,.,.) = \n",
      " -1.8158e-03 -1.1870e-02 -3.3091e-02 -5.6132e-02  2.2756e-02\n",
      "  4.6093e-02  2.1613e-02  2.9564e-02  6.4914e-02  5.7482e-02\n",
      "  2.9997e-02  6.9538e-02  9.6109e-02  2.8404e-02 -1.6552e-02\n",
      " -6.8049e-03  5.0336e-02  3.2460e-02  3.1197e-02  5.7058e-02\n",
      " -9.1694e-03 -6.4472e-03  6.1660e-02  3.8320e-02 -3.8472e-02\n",
      "\n",
      "(17,9 ,.,.) = \n",
      " -1.0742e-03  2.5132e-02 -2.1733e-02  4.5084e-02  2.3605e-03\n",
      "  4.9663e-02  3.3225e-02  4.2266e-02 -8.6892e-02  2.9739e-02\n",
      "  6.8438e-02 -1.0580e-02  7.1212e-02  4.4803e-02  5.3477e-03\n",
      "  2.2394e-03  9.9324e-02  1.1380e-01  4.0249e-02  6.8299e-02\n",
      " -1.0003e-01 -1.0297e-01  3.2689e-02 -1.5499e-02 -2.5354e-03\n",
      "     ⋮ \n",
      "\n",
      "(18,0 ,.,.) = \n",
      " -6.0449e-02 -1.1878e-01 -6.9183e-02  2.1464e-02  3.9715e-02\n",
      " -2.2396e-02 -2.9966e-02 -6.1288e-02 -8.6592e-02 -1.9407e-02\n",
      " -9.6881e-02 -5.7986e-02 -5.4720e-02  3.8694e-02 -2.6714e-02\n",
      " -2.5600e-02 -7.5831e-02 -2.9634e-02  2.5173e-03 -3.3367e-02\n",
      " -8.4449e-02 -4.5035e-02 -1.4771e-02 -1.7005e-02 -9.9115e-02\n",
      "\n",
      "(18,1 ,.,.) = \n",
      "  3.8434e-02  2.2819e-02 -5.5251e-02  2.7538e-02  1.0777e-02\n",
      " -3.1974e-02 -2.0137e-02 -7.1316e-02 -2.9303e-02 -6.6147e-02\n",
      " -5.2084e-02 -1.7227e-02 -6.3889e-02 -3.2523e-02  4.7593e-03\n",
      " -3.3255e-02  4.4487e-02  2.7438e-02  1.3722e-02  8.3884e-03\n",
      "  4.6573e-02  2.5610e-02 -7.5855e-06 -1.1581e-02 -2.7823e-02\n",
      "\n",
      "(18,2 ,.,.) = \n",
      " -2.2001e-02 -9.0782e-02 -4.0109e-02  4.7617e-02 -2.1731e-04\n",
      " -4.2581e-02  2.0243e-02  3.7345e-02  6.1281e-02  4.1842e-02\n",
      " -3.7542e-02  9.7704e-03 -1.4155e-02 -5.1803e-03 -5.1615e-03\n",
      "  8.7871e-03  4.8908e-02  9.1002e-02  3.0552e-02  4.5431e-02\n",
      " -9.3149e-02 -5.4033e-02  2.3358e-02 -7.1510e-02 -5.2667e-02\n",
      "   ...\n",
      "\n",
      "(18,7 ,.,.) = \n",
      " -8.7114e-03 -8.0702e-02 -6.1187e-02  6.6869e-02  1.1244e-01\n",
      " -8.6928e-02 -5.6073e-02  8.2770e-02  1.3519e-01 -4.9767e-02\n",
      " -1.8240e-02  1.9869e-02  4.8168e-02  6.3492e-02 -1.4513e-02\n",
      "  1.4105e-02  7.1468e-02 -7.0865e-04 -4.9006e-02 -7.3991e-02\n",
      "  3.1146e-02  9.2861e-02 -4.3075e-02 -9.6326e-02 -5.9501e-02\n",
      "\n",
      "(18,8 ,.,.) = \n",
      " -6.1665e-02  3.4716e-02 -2.8896e-02 -1.3364e-02 -1.6774e-03\n",
      " -1.5041e-02  5.1352e-02  4.6352e-02 -4.3312e-02 -1.0827e-02\n",
      "  1.7429e-02  3.9333e-02  2.1591e-02  3.1762e-02 -1.2595e-02\n",
      "  2.7801e-02 -2.7519e-02 -1.4918e-02 -3.6845e-02 -3.6475e-02\n",
      "  9.3258e-03 -1.8331e-02 -2.8897e-02 -6.6888e-02  4.8788e-02\n",
      "\n",
      "(18,9 ,.,.) = \n",
      " -4.9851e-02 -3.9608e-02 -8.0639e-02 -4.6388e-02  2.0321e-02\n",
      " -2.1772e-02 -1.0359e-01 -4.5907e-02 -8.2712e-02 -6.7920e-02\n",
      " -1.0102e-03 -7.6569e-02  5.4759e-02 -6.2198e-02  2.5138e-02\n",
      " -2.3732e-02  1.3329e-02 -3.0017e-02  4.6059e-02  2.4270e-02\n",
      "  7.4213e-02 -2.9617e-04 -4.0721e-02  2.7932e-03  2.2503e-02\n",
      "     ⋮ \n",
      "\n",
      "(19,0 ,.,.) = \n",
      "  3.3122e-02 -2.3315e-02 -2.7450e-02 -4.3275e-02  9.9985e-02\n",
      "  5.2682e-02  1.0100e-03 -1.2654e-01 -2.9379e-02 -9.0482e-03\n",
      "  2.8147e-03  1.5471e-01  4.7444e-02 -1.5515e-02  1.7949e-02\n",
      " -1.7974e-02  9.9845e-02  1.7738e-01  1.4221e-01  4.3737e-02\n",
      "  3.4032e-03  8.8568e-02  3.9112e-02  4.1876e-02  4.9972e-03\n",
      "\n",
      "(19,1 ,.,.) = \n",
      " -3.3582e-02 -1.8600e-02  3.0146e-02 -2.2848e-03  5.7631e-02\n",
      " -2.4887e-02  1.2412e-02 -2.8446e-02 -2.3516e-02  7.3764e-02\n",
      "  5.3093e-02  1.1196e-01 -2.4563e-02 -3.8623e-02 -7.0587e-02\n",
      "  2.5031e-02  1.2668e-01  9.8788e-02  8.1837e-03  1.9535e-02\n",
      " -3.5163e-02 -2.0059e-02 -3.8169e-02  7.0664e-02  6.8745e-02\n",
      "\n",
      "(19,2 ,.,.) = \n",
      " -6.6434e-03 -2.2980e-02 -6.7729e-02 -3.7103e-03 -3.1294e-02\n",
      "  3.6863e-02 -3.3596e-03 -2.8174e-02 -1.1299e-01 -1.2318e-02\n",
      " -1.5668e-03  1.1454e-01  5.0502e-02  1.7587e-03 -2.3989e-02\n",
      " -2.9470e-02  5.4826e-02  3.7800e-02  7.5996e-02  6.2941e-02\n",
      " -8.7302e-02 -3.9045e-03 -5.3019e-02  2.3020e-02 -1.0556e-01\n",
      "   ...\n",
      "\n",
      "(19,7 ,.,.) = \n",
      " -3.6926e-02 -6.9153e-02 -1.2482e-02  1.1639e-02 -1.2527e-02\n",
      "  1.8725e-02  6.0959e-02 -8.4907e-02 -8.1778e-02 -4.3081e-02\n",
      "  3.6566e-02 -7.5934e-02 -7.6092e-02 -7.2351e-02 -3.7865e-02\n",
      "  2.9871e-02  3.0657e-02  4.4996e-02  5.0765e-02 -3.6923e-02\n",
      " -9.5962e-02  4.9069e-03 -3.1250e-02 -6.7285e-02 -4.9669e-02\n",
      "\n",
      "(19,8 ,.,.) = \n",
      " -5.4333e-02 -2.9830e-03 -8.7737e-03  1.7792e-02  2.3232e-02\n",
      "  3.7248e-03  9.1955e-02 -1.2003e-02 -4.0891e-02 -4.3087e-02\n",
      "  1.6054e-02 -3.8519e-02 -2.0774e-02  8.0969e-02 -3.2495e-02\n",
      " -4.9099e-03 -1.8565e-02  1.6973e-02 -4.2003e-02  3.9286e-02\n",
      "  2.2510e-02  4.7421e-02  4.8580e-02  1.3529e-02  2.9826e-02\n",
      "\n",
      "(19,9 ,.,.) = \n",
      " -3.9611e-02 -5.1517e-02 -9.1571e-02  1.5929e-02  4.1393e-02\n",
      " -4.6854e-02  4.6607e-02  2.9328e-02 -1.0111e-03 -1.0746e-02\n",
      " -4.5147e-02  2.0799e-02  4.9559e-02  2.3412e-02 -8.6379e-02\n",
      " -9.7175e-02 -1.0794e-02  1.2169e-01 -6.3197e-03  2.0450e-02\n",
      " -9.1908e-02 -2.2905e-02 -2.3070e-02  4.9691e-02  5.7804e-02\n",
      "[torch.FloatTensor of size 20x10x5x5]\n",
      ", Parameter containing:\n",
      "1.00000e-02 *\n",
      "  2.4103\n",
      "  2.2232\n",
      "  2.3224\n",
      "  3.2518\n",
      " -4.2167\n",
      " -6.2022\n",
      "  2.6381\n",
      "  0.0702\n",
      "  4.8453\n",
      " -3.1157\n",
      " -5.2136\n",
      "  6.9174\n",
      " -0.4145\n",
      "  2.3497\n",
      " -5.2485\n",
      " -2.5922\n",
      " -6.3356\n",
      "  4.3994\n",
      " -0.1977\n",
      "  6.0233\n",
      "[torch.FloatTensor of size 20]\n",
      ", Parameter containing:\n",
      "-1.3847e-03  1.2418e-02 -4.1320e-02  ...   5.8005e-02 -5.0558e-02  4.3361e-02\n",
      " 2.3902e-02 -4.8468e-02  6.0686e-03  ...   6.7830e-03 -2.6844e-02  3.1665e-02\n",
      " 1.9037e-02  3.5444e-02  5.2060e-02  ...   1.0132e-02  3.4025e-02 -1.7027e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-1.1197e-02  9.4759e-03 -3.4992e-03  ...  -2.9874e-03 -1.5373e-02 -4.2577e-03\n",
      " 3.8235e-02  4.4457e-02  1.3205e-02  ...   1.0407e-01  5.5560e-03 -3.1458e-02\n",
      " 3.7971e-02  8.6876e-02  6.0070e-02  ...   8.2687e-02  7.1484e-03 -2.5846e-02\n",
      "[torch.FloatTensor of size 50x320]\n",
      ", Parameter containing:\n",
      "1.00000e-02 *\n",
      "  3.9259\n",
      " -2.7801\n",
      "  5.9484\n",
      "  0.3870\n",
      "  0.0654\n",
      "  0.4366\n",
      " -3.8175\n",
      " -5.2667\n",
      "  3.1918\n",
      " -2.8017\n",
      "  0.9092\n",
      " -3.3857\n",
      "  6.1078\n",
      "  0.9712\n",
      "  6.9119\n",
      "  4.1210\n",
      "  4.8603\n",
      " -0.7278\n",
      " -0.2234\n",
      " -0.5233\n",
      "  6.0273\n",
      "  4.7747\n",
      "  4.2506\n",
      " -4.6518\n",
      "  2.6726\n",
      " -0.4177\n",
      "  6.2178\n",
      "  2.6575\n",
      "  6.6797\n",
      "  6.1835\n",
      " -2.5790\n",
      "  1.2465\n",
      "  0.3375\n",
      "  2.6311\n",
      "  7.5150\n",
      "  3.0269\n",
      "  6.5540\n",
      "  3.4880\n",
      "  6.0364\n",
      "  4.7539\n",
      "  5.9535\n",
      " -3.6503\n",
      "  4.0583\n",
      "  4.9907\n",
      " -3.3656\n",
      "  3.3834\n",
      "  3.0907\n",
      " -1.2063\n",
      "  3.7742\n",
      "  1.6067\n",
      "[torch.FloatTensor of size 50]\n",
      ", Parameter containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      " 0.1477  0.1018  0.1016 -0.0382  0.1128  0.1965 -0.0506 -0.0964  0.0836 -0.2016\n",
      "-0.1293  0.1281  0.0370  0.3567 -0.2005 -0.1840 -0.1748 -0.0572  0.0549  0.1659\n",
      " 0.1997 -0.1053  0.1600 -0.0552 -0.0826  0.2001  0.1377 -0.0333 -0.2012 -0.0510\n",
      " 0.1100 -0.0330  0.1487  0.0739 -0.0973 -0.0912  0.1785  0.0991 -0.1605 -0.1838\n",
      "-0.1333  0.0128 -0.2240  0.0585  0.1387 -0.1278 -0.0394  0.1602  0.0579  0.1377\n",
      "-0.1413 -0.0242  0.0982  0.0677  0.1842 -0.0615  0.1171 -0.0180  0.1870 -0.1211\n",
      " 0.0372  0.0738  0.1180 -0.0735 -0.0238  0.0645 -0.1982 -0.1309  0.1674  0.1320\n",
      " 0.1310 -0.0541 -0.0646 -0.0807 -0.0420  0.1885 -0.0405 -0.0387 -0.1094 -0.1513\n",
      " 0.1259 -0.0311  0.1541 -0.0009 -0.0785  0.0203 -0.0398  0.0255  0.1484  0.1100\n",
      "-0.1684 -0.0412 -0.1358 -0.0772 -0.0268 -0.0342  0.1434  0.1218 -0.1373  0.0223\n",
      "\n",
      "Columns 10 to 19 \n",
      "-0.1136  0.2126 -0.1308 -0.2112  0.0963 -0.1730  0.1947  0.0949 -0.0508 -0.2381\n",
      " 0.0325 -0.0980  0.2016  0.1509 -0.0673 -0.0402 -0.0439 -0.2264  0.1787 -0.2182\n",
      "-0.2017 -0.0355 -0.1082  0.1017 -0.2163  0.2353 -0.0243  0.0549  0.1908 -0.1015\n",
      "-0.0964  0.0317 -0.0928  0.1830  0.1415  0.0986  0.0663  0.0973 -0.0015  0.1273\n",
      " 0.1184 -0.0783  0.1238 -0.1530 -0.0932 -0.0871 -0.0027 -0.2409  0.1527  0.0047\n",
      " 0.1510  0.0067 -0.0099  0.1092  0.1879 -0.1695 -0.0190  0.0267 -0.1364  0.1082\n",
      " 0.1586 -0.1355 -0.1967  0.1296  0.0998 -0.0612 -0.1320 -0.2738  0.1418 -0.0848\n",
      " 0.0996  0.1568  0.2472 -0.1250  0.1419  0.2132  0.2175  0.1145  0.1516 -0.0674\n",
      "-0.1647 -0.0370 -0.1450  0.0138 -0.1238 -0.0366 -0.0785 -0.0324  0.0356  0.0781\n",
      " 0.1094  0.2124  0.1955 -0.1873 -0.0722 -0.0492  0.0701  0.1082 -0.1293  0.0235\n",
      "\n",
      "Columns 20 to 29 \n",
      " 0.1310  0.0380 -0.2520 -0.0738  0.1217  0.2162  0.2040 -0.0424  0.1010 -0.2357\n",
      "-0.2172 -0.0729  0.0824 -0.0110 -0.1400 -0.0971  0.1895 -0.0258  0.1314  0.1775\n",
      "-0.0480  0.1366 -0.0286 -0.1480 -0.1624  0.0439  0.2019  0.0006  0.1049  0.1517\n",
      " 0.0275 -0.1279  0.0874  0.1821 -0.1721 -0.1114  0.0692 -0.1311  0.1232 -0.1766\n",
      "-0.2504  0.1282  0.0780  0.0920  0.0598  0.0857 -0.1250  0.2554 -0.1195 -0.0429\n",
      " 0.1456 -0.0726 -0.1765  0.0785 -0.0621  0.0682 -0.1061 -0.0115  0.1326 -0.0830\n",
      " 0.1196  0.1000 -0.2938 -0.2347  0.0862  0.0122 -0.1044  0.2667  0.1005  0.1520\n",
      "-0.1366 -0.1982  0.0198  0.1633 -0.0939 -0.0719  0.1876 -0.0432 -0.2152 -0.1059\n",
      " 0.1516  0.1746  0.1255 -0.1099 -0.1317 -0.0417 -0.0131 -0.0558  0.0938 -0.1319\n",
      "-0.0690  0.0947  0.0874  0.1593  0.2110 -0.1100 -0.1883 -0.1983 -0.1481 -0.1897\n",
      "\n",
      "Columns 30 to 39 \n",
      " 0.1129 -0.1700 -0.0056  0.0825 -0.2435  0.0322  0.0218 -0.1898  0.0396 -0.0905\n",
      " 0.1072 -0.1882  0.0207 -0.2847  0.1271 -0.2363  0.2028 -0.1954  0.1954 -0.1541\n",
      "-0.0445  0.1098 -0.0297 -0.1985  0.0764 -0.0102  0.0057 -0.2059  0.1438 -0.1660\n",
      " 0.1278 -0.1270  0.0222 -0.1973  0.1450 -0.0614 -0.1073  0.1303 -0.1172  0.0050\n",
      "-0.2203  0.1141 -0.0359  0.0999  0.1579  0.1856  0.2042 -0.1683  0.0198  0.1705\n",
      " 0.1243  0.1347 -0.0723  0.0462  0.0450  0.0774 -0.1446  0.1520 -0.0573 -0.1598\n",
      "-0.1253 -0.1640  0.3062  0.1212 -0.2669  0.1517 -0.0365 -0.0734 -0.1157 -0.1061\n",
      " 0.0637 -0.1031  0.0462  0.0567  0.1387 -0.1925  0.1481 -0.2531  0.2095  0.2210\n",
      "-0.1588 -0.1511  0.0549 -0.0906  0.1119 -0.1254  0.1723  0.1298 -0.1688 -0.1125\n",
      "-0.0485  0.1330  0.0478  0.0325  0.1440  0.1160  0.1526  0.0511  0.0119  0.1511\n",
      "\n",
      "Columns 40 to 49 \n",
      "-0.0246 -0.0631  0.1916 -0.1842 -0.0315 -0.1910 -0.0694 -0.2658  0.1493  0.1994\n",
      " 0.1087 -0.0739 -0.1404  0.1753 -0.0435  0.0732  0.1269  0.0536 -0.2302 -0.0500\n",
      " 0.0565  0.1978  0.1646  0.2250 -0.1451  0.1308 -0.0135 -0.1590  0.1432 -0.0844\n",
      " 0.0158  0.0386  0.1570  0.2082 -0.1325  0.0136  0.1777 -0.0092 -0.1474 -0.0620\n",
      "-0.1090  0.2367  0.0126 -0.1231  0.0712 -0.1322 -0.2049  0.1073  0.0124 -0.0258\n",
      " 0.2095  0.0023 -0.1747 -0.1388 -0.1343 -0.2219 -0.0892  0.1264  0.0110  0.1721\n",
      "-0.0857  0.2039 -0.1134 -0.0392  0.0014 -0.1681 -0.1337 -0.2350  0.1297  0.1849\n",
      " 0.1149 -0.0979 -0.0415  0.0182 -0.1485  0.1330  0.0313  0.1078 -0.2219 -0.2123\n",
      " 0.2252 -0.0951 -0.1139 -0.0991  0.0537  0.1619  0.1546  0.1003  0.1167  0.2019\n",
      " 0.1620 -0.1542  0.0570 -0.1612 -0.0106  0.1323 -0.1010  0.1257  0.0457 -0.1273\n",
      "[torch.FloatTensor of size 10x50]\n",
      ", Parameter containing:\n",
      "-0.0827\n",
      " 0.1294\n",
      "-0.0102\n",
      " 0.0677\n",
      "-0.1396\n",
      "-0.0263\n",
      "-0.1230\n",
      "-0.1337\n",
      " 0.1562\n",
      " 0.1280\n",
      "[torch.FloatTensor of size 10]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(list(x.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
